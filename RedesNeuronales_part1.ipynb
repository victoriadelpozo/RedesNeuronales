{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Victoriadelpozo-a11-mod1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlnPu4epau31fAGNZoVDjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriadelpozo/RedesNeuronales/blob/main/RedesNeuronales_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "1DQAXVwrH6K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9b-dRptfpla",
        "outputId": "47da75ea-5c5d-46e3-da16-ccd42c624887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"example_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 817\n",
            "Trainable params: 817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(name='example_model')\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(32,), name='layer_1'))\n",
        "model.add(layers.Dense(16, activation='relu', name='layer_2'))\n",
        "model.add(layers.Dense(1, name='output_layer'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32,), name='input_layer')\n",
        "l_1 = layers.Dense(16, activation='relu', name='layer_1')(inputs)\n",
        "l_2 = layers.Dense(16, activation='relu', name='layer_2')(l_1)    \n",
        "outputs = layers.Dense(1, name='output_layer')(l_2)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jb6QoFoIr8S",
        "outputId": "60fc4fcc-3512-4e72-e682-44fcd5e6ec30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"example_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 32)]              0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 817\n",
            "Trainable params: 817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOwVEyMAI0UJ",
        "outputId": "1422062e-86de-40f3-f335-aa12727fccf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f0f45c3b2d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f0f45c3b310>,\n",
              " <keras.layers.core.dense.Dense at 0x7f0f45c3b9d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f0f45bc4750>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = model.layers[1].get_weights()"
      ],
      "metadata": {
        "id": "2N-ovUBIJGh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW_qmUzhJKDk",
        "outputId": "ec3d1678-c5a5-44ed-9b75-833f055ea660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiDpxRTwJME-",
        "outputId": "11a3ab8f-5949-4acd-c519-02cbe0ea72c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pesos de la primera capa oculta:\\n{}\".format(weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdixyPzwJQH_",
        "outputId": "8d706e82-b86e-47d0-fabf-6fbe5c937ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos de la primera capa oculta:\n",
            "[[-0.3189633  -0.06935078 -0.06388694  0.2593235  -0.33196896  0.23336944\n",
            "   0.31085923 -0.26125035 -0.28128392  0.30433032 -0.07418704 -0.00316802\n",
            "   0.18244913  0.05119374  0.24089298  0.30573592]\n",
            " [-0.02101129 -0.04733706 -0.2663024  -0.11201175 -0.28477916  0.26066795\n",
            "   0.24308732  0.02128273  0.34717295 -0.07271814  0.0383195  -0.06002513\n",
            "   0.05042887  0.14823803 -0.05608287  0.04013392]\n",
            " [ 0.27990773  0.1293717   0.03854296  0.11984828  0.2894853   0.15960112\n",
            "   0.20422152 -0.08301377  0.13234338 -0.31588852  0.3142688   0.19260839\n",
            "  -0.12754269 -0.05680189  0.23800746  0.17650768]\n",
            " [ 0.20139626  0.13436475 -0.31869835  0.07938385  0.26294574 -0.25386065\n",
            "  -0.3132096   0.25847557  0.2966543   0.05687758  0.19664767 -0.06182489\n",
            "   0.3403112  -0.19149168  0.26151565 -0.26416227]\n",
            " [-0.04338858 -0.21993035  0.08097565  0.07390568  0.27950332  0.1379892\n",
            "   0.16002223  0.12441498  0.20505056 -0.09893906 -0.09686863  0.21547177\n",
            "   0.06284001  0.15880504  0.1007705  -0.32892817]\n",
            " [-0.0397588   0.0939014  -0.05415964 -0.2293226  -0.13675168  0.33075938\n",
            "  -0.03986132  0.18077055 -0.17878853 -0.18272783  0.09407943 -0.16739438\n",
            "  -0.21710508  0.32515714  0.14361337 -0.13497595]\n",
            " [-0.10276759  0.14608139 -0.15175714 -0.32012123 -0.23326889  0.23075494\n",
            "   0.3333266   0.21513024 -0.18544209 -0.12116385  0.02660108 -0.05384168\n",
            "   0.07084531 -0.3164597  -0.01815847 -0.27572417]\n",
            " [-0.03331926  0.23949197 -0.14706165  0.29358152 -0.26416236 -0.26677766\n",
            "   0.28147206  0.06705076  0.17946741 -0.16389796 -0.30193716 -0.32626078\n",
            "   0.2937111   0.29280916 -0.23586658  0.2671037 ]\n",
            " [-0.3503661  -0.01641619  0.0902493   0.05116424  0.3122413  -0.1900865\n",
            "  -0.236043    0.27572015  0.08149901 -0.26412764 -0.3330753  -0.01053351\n",
            "   0.14201683 -0.13043404 -0.22528704  0.08890474]\n",
            " [ 0.26259473 -0.31214294  0.01425433 -0.19352594 -0.04276791 -0.3079832\n",
            "   0.26031306 -0.1887448   0.21185288  0.06600854  0.10492358 -0.25994498\n",
            "  -0.15167968  0.02672052  0.02164838 -0.13608198]\n",
            " [ 0.20496276  0.06510684 -0.0099169   0.14332584  0.15186855  0.2088333\n",
            "   0.22623011  0.15519878 -0.26636708 -0.202544   -0.02488232  0.31760707\n",
            "  -0.24032605 -0.08719903  0.12045789  0.13070732]\n",
            " [-0.2644019  -0.12565501 -0.26744998 -0.15487956 -0.07888129  0.19998536\n",
            "  -0.29580715  0.07463178 -0.23408687 -0.16006133  0.22993019  0.24145111\n",
            "   0.11605835 -0.18319684  0.1865358   0.2988796 ]\n",
            " [ 0.3452572  -0.22764592  0.16688696  0.23298904 -0.22088051 -0.25571042\n",
            "   0.1343489  -0.14614673  0.13458407  0.14776424 -0.21756598  0.2905065\n",
            "   0.11610556  0.29396757 -0.28593332 -0.34646893]\n",
            " [ 0.0782274  -0.01372564 -0.23693568 -0.21053042  0.2688392   0.21757594\n",
            "  -0.22351097 -0.11216027  0.25022998  0.21938345  0.312654   -0.09899494\n",
            "  -0.10342568  0.2938352  -0.16417243 -0.02955446]\n",
            " [-0.10484719 -0.16631138 -0.04640773 -0.06724268 -0.24369814  0.23145995\n",
            "  -0.04306903 -0.2818913   0.2558966  -0.20642869 -0.09519532  0.08226246\n",
            "  -0.14572889 -0.28547257  0.02006537  0.07306519]\n",
            " [-0.28166452  0.17536268  0.1672611   0.15453032 -0.01620823  0.26674715\n",
            "   0.00980815  0.30948862  0.15244934 -0.11132643  0.19269726  0.00649229\n",
            "   0.08743337 -0.21582103 -0.21292512 -0.07902804]\n",
            " [ 0.33149055 -0.06507802 -0.0868493  -0.13141674  0.16064236  0.29435095\n",
            "   0.22918615 -0.18802324  0.28694192 -0.3173909  -0.29672104  0.11926007\n",
            "   0.21454296 -0.34704617  0.2780623   0.3252904 ]\n",
            " [ 0.08321214  0.09186336 -0.11292168 -0.09800196 -0.34323508  0.13462505\n",
            "  -0.01018614  0.1542606  -0.00153196 -0.07931834 -0.131973   -0.26380444\n",
            "  -0.01748714  0.24587157 -0.11715272  0.02260503]\n",
            " [ 0.01416716  0.195919    0.08657509 -0.1296249   0.28961858 -0.2759499\n",
            "  -0.16314295  0.18826035 -0.20750563 -0.13282655 -0.07993791  0.15540859\n",
            "   0.21843633 -0.27394742 -0.07632509  0.04538837]\n",
            " [ 0.09714732 -0.15476154 -0.13758695 -0.1254763  -0.10618469  0.08643442\n",
            "  -0.17689748 -0.3418198  -0.31053957  0.32831368  0.01580489  0.12021714\n",
            "   0.15053537  0.3262126  -0.21213107  0.05287972]\n",
            " [ 0.12145069  0.16224656  0.28335968 -0.27802673  0.27325216  0.35009053\n",
            "   0.27178225 -0.3456668   0.23575309  0.23685923  0.10456026  0.24193689\n",
            "  -0.292985    0.26933363 -0.16215898  0.12686571]\n",
            " [ 0.10958019 -0.1333147  -0.32536718  0.24754992 -0.06863767 -0.15925524\n",
            "  -0.04557389 -0.24199447  0.09172013  0.25617233 -0.08550701 -0.02448469\n",
            "   0.21081641 -0.17823143  0.22014353  0.29011443]\n",
            " [-0.29224423  0.19280532  0.28042158 -0.21274102 -0.08413085 -0.29231513\n",
            "   0.05936587 -0.13978331 -0.21693766  0.06708127 -0.17430301 -0.17661342\n",
            "   0.21147612 -0.19298865 -0.33258525  0.04780665]\n",
            " [-0.2655763   0.15840337  0.10327342  0.3254604  -0.04073763  0.07277101\n",
            "   0.0738503   0.2271047  -0.17472777  0.3369836  -0.11278631 -0.15035458\n",
            "  -0.13205628  0.04000673  0.24439332  0.17933121]\n",
            " [ 0.02412385  0.27785823 -0.22027156 -0.02534038  0.24943641  0.06995845\n",
            "   0.00866336 -0.09775716  0.00238737  0.24851468 -0.0312857   0.12082312\n",
            "   0.25618926  0.09656063 -0.30168232 -0.30262607]\n",
            " [ 0.23239079  0.09379148 -0.10337129 -0.06675866 -0.03948292  0.07573351\n",
            "   0.08185804 -0.10971212  0.3046573  -0.2651132   0.2869763  -0.11981152\n",
            "  -0.11674179  0.18521759  0.2303159  -0.2726596 ]\n",
            " [ 0.14959821 -0.18732166  0.01537955 -0.31377342  0.09828046 -0.04306117\n",
            "  -0.26067454  0.24728355  0.07871243  0.2532921   0.31965223 -0.1477129\n",
            "   0.10218832  0.32848063 -0.06324455  0.20930639]\n",
            " [-0.26854354  0.2866147   0.25640336 -0.28702307 -0.22627234  0.23029044\n",
            "  -0.26986247  0.03204611 -0.12147909 -0.0903143  -0.27412158  0.02951503\n",
            "   0.26378074 -0.16560172 -0.15474764  0.13380519]\n",
            " [ 0.25694486  0.22688171  0.03256992 -0.1873124  -0.18550193 -0.25702405\n",
            "   0.25947145 -0.2357504  -0.09869292  0.03537485 -0.05475262 -0.2706793\n",
            "  -0.2539362  -0.07210633 -0.31271082  0.16366175]\n",
            " [-0.03147966 -0.08501467  0.2981175  -0.25059733 -0.02665418 -0.06746674\n",
            "   0.2958894   0.18044075  0.01508993  0.20840105 -0.30323452  0.19935367\n",
            "  -0.00629193 -0.26409274  0.31854227 -0.22252946]\n",
            " [ 0.26049128 -0.16782968 -0.1604061  -0.10971987 -0.10428908 -0.15800145\n",
            "  -0.21691279 -0.17703775 -0.17689024 -0.23837921 -0.2990356  -0.13439415\n",
            "  -0.01185954  0.22960523 -0.34923872  0.14187294]\n",
            " [ 0.1782935  -0.09781247  0.15458933 -0.1959965  -0.12382652  0.33088604\n",
            "   0.24817178  0.28071645  0.12759832 -0.34157482 -0.07306284 -0.18442585\n",
            "  -0.19327264 -0.2989647   0.24868408  0.14978912]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "data = pd.DataFrame(\n",
        "    data=np.c_[\n",
        "        iris['data'],\n",
        "        iris['target']\n",
        "    ],\n",
        "    columns=iris['feature_names']+['target']\n",
        ")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1U4Bnm2-JT3d",
        "outputId": "55a7210b-8b9f-46c3-87e8-8e15e23ec27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-65003c11-014d-4c1c-98e6-ab373e4d10f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65003c11-014d-4c1c-98e6-ab373e4d10f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65003c11-014d-4c1c-98e6-ab373e4d10f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65003c11-014d-4c1c-98e6-ab373e4d10f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2     0.0\n",
              "1                4.9               3.0  ...               0.2     0.0\n",
              "2                4.7               3.2  ...               0.2     0.0\n",
              "3                4.6               3.1  ...               0.2     0.0\n",
              "4                5.0               3.6  ...               0.2     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,0:4].values\n",
        "y = data.iloc[:,4].values\n"
      ],
      "metadata": {
        "id": "DM-s9h9NmwTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder =  LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)\n",
        "\n",
        "Y = pd.get_dummies(y1).values"
      ],
      "metadata": {
        "id": "sLD4rA9mpFpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=0\n",
        ")"
      ],
      "metadata": {
        "id": "oqaARSJZpGqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = tf.keras.Input(shape=(4,), name='input_layer')  # entrada\n",
        "\n",
        "l_1 = layers.Dense(16, activation='relu', name='layer_1')(inputs)  # capa oculta 1\n",
        "l_2 = layers.Dense(16, activation='relu', name='layer_2')(l_1)  # capa oculta 2\n",
        "\n",
        "outputs = layers.Dense(3, activation='softmax', name='output_layer')(l_2)  # salidas\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')  # creamos el modelo"
      ],
      "metadata": {
        "id": "shPJQ-jWpJKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLlLXL8tpRH8",
        "outputId": "a77de40a-2198-4f29-e60e-b7c8873c3784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"example_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 4)]               0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 403\n",
            "Trainable params: 403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "X0rJC6iBpYhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=250, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBHJHzvwpfLj",
        "outputId": "84a19f40-ba1c-4208-f4b5-2ba4e24d244a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3/3 [==============================] - 1s 106ms/step - loss: 1.3347 - accuracy: 0.3438 - val_loss: 1.4386 - val_accuracy: 0.2500\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1800 - accuracy: 0.3438 - val_loss: 1.2309 - val_accuracy: 0.2500\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0773 - accuracy: 0.2917 - val_loss: 1.0917 - val_accuracy: 0.2917\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0201 - accuracy: 0.4479 - val_loss: 1.0051 - val_accuracy: 0.5000\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9818 - accuracy: 0.5833 - val_loss: 0.9574 - val_accuracy: 0.6667\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.9526 - accuracy: 0.6042 - val_loss: 0.9236 - val_accuracy: 0.7083\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9189 - accuracy: 0.6354 - val_loss: 0.9055 - val_accuracy: 0.6667\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8782 - accuracy: 0.7396 - val_loss: 0.8941 - val_accuracy: 0.7500\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8481 - accuracy: 0.7500 - val_loss: 0.8902 - val_accuracy: 0.5417\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8218 - accuracy: 0.7292 - val_loss: 0.8819 - val_accuracy: 0.5417\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7987 - accuracy: 0.7292 - val_loss: 0.8671 - val_accuracy: 0.5417\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7738 - accuracy: 0.7292 - val_loss: 0.8461 - val_accuracy: 0.5417\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7509 - accuracy: 0.7292 - val_loss: 0.8306 - val_accuracy: 0.5417\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7319 - accuracy: 0.7292 - val_loss: 0.8139 - val_accuracy: 0.5417\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7152 - accuracy: 0.7292 - val_loss: 0.8008 - val_accuracy: 0.5417\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7019 - accuracy: 0.7396 - val_loss: 0.7913 - val_accuracy: 0.5833\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.7708 - val_loss: 0.7810 - val_accuracy: 0.6250\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.8021 - val_loss: 0.7742 - val_accuracy: 0.6250\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6668 - accuracy: 0.8021 - val_loss: 0.7638 - val_accuracy: 0.6250\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6545 - accuracy: 0.8021 - val_loss: 0.7559 - val_accuracy: 0.6250\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.8021 - val_loss: 0.7439 - val_accuracy: 0.6667\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6306 - accuracy: 0.8125 - val_loss: 0.7324 - val_accuracy: 0.7083\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6195 - accuracy: 0.8125 - val_loss: 0.7239 - val_accuracy: 0.7083\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6078 - accuracy: 0.8229 - val_loss: 0.7075 - val_accuracy: 0.7083\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.5984 - accuracy: 0.8542 - val_loss: 0.6892 - val_accuracy: 0.7917\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5861 - accuracy: 0.8854 - val_loss: 0.6819 - val_accuracy: 0.7917\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5761 - accuracy: 0.8542 - val_loss: 0.6774 - val_accuracy: 0.7917\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5650 - accuracy: 0.8542 - val_loss: 0.6669 - val_accuracy: 0.7917\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5554 - accuracy: 0.8542 - val_loss: 0.6585 - val_accuracy: 0.7917\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5450 - accuracy: 0.8646 - val_loss: 0.6444 - val_accuracy: 0.8333\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5353 - accuracy: 0.8958 - val_loss: 0.6316 - val_accuracy: 0.8333\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.5264 - accuracy: 0.8958 - val_loss: 0.6248 - val_accuracy: 0.8333\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.5168 - accuracy: 0.8958 - val_loss: 0.6164 - val_accuracy: 0.8333\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5080 - accuracy: 0.8958 - val_loss: 0.6012 - val_accuracy: 0.8333\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.9062 - val_loss: 0.5918 - val_accuracy: 0.8333\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4901 - accuracy: 0.9062 - val_loss: 0.5843 - val_accuracy: 0.8333\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4816 - accuracy: 0.9062 - val_loss: 0.5760 - val_accuracy: 0.8333\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4738 - accuracy: 0.9167 - val_loss: 0.5667 - val_accuracy: 0.8333\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4652 - accuracy: 0.9167 - val_loss: 0.5610 - val_accuracy: 0.8333\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4582 - accuracy: 0.9062 - val_loss: 0.5599 - val_accuracy: 0.8333\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4501 - accuracy: 0.9062 - val_loss: 0.5471 - val_accuracy: 0.8333\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4421 - accuracy: 0.9271 - val_loss: 0.5372 - val_accuracy: 0.8333\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4359 - accuracy: 0.9375 - val_loss: 0.5303 - val_accuracy: 0.8333\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4284 - accuracy: 0.9479 - val_loss: 0.5191 - val_accuracy: 0.8333\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.9479 - val_loss: 0.5145 - val_accuracy: 0.8333\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4143 - accuracy: 0.9479 - val_loss: 0.5104 - val_accuracy: 0.8333\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4090 - accuracy: 0.9479 - val_loss: 0.4955 - val_accuracy: 0.8333\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.4022 - accuracy: 0.9479 - val_loss: 0.4949 - val_accuracy: 0.8333\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3951 - accuracy: 0.9479 - val_loss: 0.4844 - val_accuracy: 0.8333\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3891 - accuracy: 0.9479 - val_loss: 0.4749 - val_accuracy: 0.8333\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.9479 - val_loss: 0.4697 - val_accuracy: 0.8333\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3771 - accuracy: 0.9479 - val_loss: 0.4694 - val_accuracy: 0.8333\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.3737 - accuracy: 0.9479 - val_loss: 0.4682 - val_accuracy: 0.8333\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3662 - accuracy: 0.9479 - val_loss: 0.4525 - val_accuracy: 0.8333\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3601 - accuracy: 0.9479 - val_loss: 0.4419 - val_accuracy: 0.8333\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3557 - accuracy: 0.9583 - val_loss: 0.4311 - val_accuracy: 0.8750\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3508 - accuracy: 0.9583 - val_loss: 0.4307 - val_accuracy: 0.8333\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3446 - accuracy: 0.9479 - val_loss: 0.4287 - val_accuracy: 0.8333\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3404 - accuracy: 0.9479 - val_loss: 0.4285 - val_accuracy: 0.8333\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.9479 - val_loss: 0.4204 - val_accuracy: 0.8333\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3303 - accuracy: 0.9479 - val_loss: 0.4099 - val_accuracy: 0.8333\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3257 - accuracy: 0.9583 - val_loss: 0.4012 - val_accuracy: 0.8750\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3215 - accuracy: 0.9583 - val_loss: 0.4001 - val_accuracy: 0.8750\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 0.9583 - val_loss: 0.3953 - val_accuracy: 0.8750\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3131 - accuracy: 0.9583 - val_loss: 0.3903 - val_accuracy: 0.8750\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3079 - accuracy: 0.9583 - val_loss: 0.3816 - val_accuracy: 0.8750\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3043 - accuracy: 0.9688 - val_loss: 0.3753 - val_accuracy: 0.8750\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3006 - accuracy: 0.9688 - val_loss: 0.3769 - val_accuracy: 0.8750\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2967 - accuracy: 0.9583 - val_loss: 0.3749 - val_accuracy: 0.8750\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2923 - accuracy: 0.9688 - val_loss: 0.3629 - val_accuracy: 0.8750\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2881 - accuracy: 0.9688 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2844 - accuracy: 0.9688 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2806 - accuracy: 0.9688 - val_loss: 0.3498 - val_accuracy: 0.8750\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2769 - accuracy: 0.9688 - val_loss: 0.3461 - val_accuracy: 0.8750\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2742 - accuracy: 0.9688 - val_loss: 0.3456 - val_accuracy: 0.8750\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2702 - accuracy: 0.9688 - val_loss: 0.3400 - val_accuracy: 0.8750\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2694 - accuracy: 0.9688 - val_loss: 0.3248 - val_accuracy: 0.9167\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2642 - accuracy: 0.9688 - val_loss: 0.3275 - val_accuracy: 0.8750\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2600 - accuracy: 0.9688 - val_loss: 0.3267 - val_accuracy: 0.8750\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2580 - accuracy: 0.9688 - val_loss: 0.3301 - val_accuracy: 0.8750\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2539 - accuracy: 0.9688 - val_loss: 0.3212 - val_accuracy: 0.8750\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2504 - accuracy: 0.9688 - val_loss: 0.3114 - val_accuracy: 0.8750\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2496 - accuracy: 0.9688 - val_loss: 0.3005 - val_accuracy: 0.9167\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2450 - accuracy: 0.9688 - val_loss: 0.3024 - val_accuracy: 0.8750\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2416 - accuracy: 0.9688 - val_loss: 0.3081 - val_accuracy: 0.8750\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2387 - accuracy: 0.9688 - val_loss: 0.3004 - val_accuracy: 0.8750\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2339 - accuracy: 0.9688 - val_loss: 0.2938 - val_accuracy: 0.8750\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2297 - accuracy: 0.9688 - val_loss: 0.2826 - val_accuracy: 0.9167\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2255 - accuracy: 0.9688 - val_loss: 0.2812 - val_accuracy: 0.9167\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2235 - accuracy: 0.9688 - val_loss: 0.2831 - val_accuracy: 0.8750\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2200 - accuracy: 0.9688 - val_loss: 0.2772 - val_accuracy: 0.9167\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2176 - accuracy: 0.9688 - val_loss: 0.2698 - val_accuracy: 0.9167\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2155 - accuracy: 0.9688 - val_loss: 0.2581 - val_accuracy: 0.9167\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2120 - accuracy: 0.9688 - val_loss: 0.2576 - val_accuracy: 0.9167\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2087 - accuracy: 0.9688 - val_loss: 0.2595 - val_accuracy: 0.9167\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2064 - accuracy: 0.9688 - val_loss: 0.2596 - val_accuracy: 0.9167\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2045 - accuracy: 0.9688 - val_loss: 0.2615 - val_accuracy: 0.9167\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2017 - accuracy: 0.9688 - val_loss: 0.2522 - val_accuracy: 0.9167\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1986 - accuracy: 0.9688 - val_loss: 0.2466 - val_accuracy: 0.9167\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1969 - accuracy: 0.9688 - val_loss: 0.2402 - val_accuracy: 0.9167\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1944 - accuracy: 0.9688 - val_loss: 0.2410 - val_accuracy: 0.9167\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1931 - accuracy: 0.9688 - val_loss: 0.2422 - val_accuracy: 0.9167\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9688 - val_loss: 0.2441 - val_accuracy: 0.9167\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1887 - accuracy: 0.9688 - val_loss: 0.2397 - val_accuracy: 0.9167\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1857 - accuracy: 0.9688 - val_loss: 0.2253 - val_accuracy: 0.9167\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1847 - accuracy: 0.9792 - val_loss: 0.2170 - val_accuracy: 0.9167\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1824 - accuracy: 0.9792 - val_loss: 0.2199 - val_accuracy: 0.9167\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1793 - accuracy: 0.9688 - val_loss: 0.2275 - val_accuracy: 0.9167\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1782 - accuracy: 0.9688 - val_loss: 0.2349 - val_accuracy: 0.9167\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1775 - accuracy: 0.9688 - val_loss: 0.2235 - val_accuracy: 0.9167\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.9688 - val_loss: 0.2123 - val_accuracy: 0.9167\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1724 - accuracy: 0.9688 - val_loss: 0.2157 - val_accuracy: 0.9167\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1704 - accuracy: 0.9688 - val_loss: 0.2140 - val_accuracy: 0.9167\n",
            "Epoch 114/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1687 - accuracy: 0.9688 - val_loss: 0.2153 - val_accuracy: 0.9167\n",
            "Epoch 115/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1670 - accuracy: 0.9688 - val_loss: 0.2129 - val_accuracy: 0.9167\n",
            "Epoch 116/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1656 - accuracy: 0.9688 - val_loss: 0.2043 - val_accuracy: 0.9167\n",
            "Epoch 117/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1639 - accuracy: 0.9688 - val_loss: 0.2055 - val_accuracy: 0.9167\n",
            "Epoch 118/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1620 - accuracy: 0.9688 - val_loss: 0.2016 - val_accuracy: 0.9167\n",
            "Epoch 119/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1619 - accuracy: 0.9688 - val_loss: 0.1980 - val_accuracy: 0.9167\n",
            "Epoch 120/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1591 - accuracy: 0.9688 - val_loss: 0.2041 - val_accuracy: 0.9167\n",
            "Epoch 121/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1578 - accuracy: 0.9688 - val_loss: 0.2068 - val_accuracy: 0.9167\n",
            "Epoch 122/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1563 - accuracy: 0.9688 - val_loss: 0.2007 - val_accuracy: 0.9167\n",
            "Epoch 123/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1545 - accuracy: 0.9688 - val_loss: 0.1936 - val_accuracy: 0.9167\n",
            "Epoch 124/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1538 - accuracy: 0.9792 - val_loss: 0.1848 - val_accuracy: 0.9167\n",
            "Epoch 125/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1520 - accuracy: 0.9792 - val_loss: 0.1878 - val_accuracy: 0.9167\n",
            "Epoch 126/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1502 - accuracy: 0.9688 - val_loss: 0.1916 - val_accuracy: 0.9167\n",
            "Epoch 127/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1492 - accuracy: 0.9688 - val_loss: 0.1939 - val_accuracy: 0.9167\n",
            "Epoch 128/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1489 - accuracy: 0.9688 - val_loss: 0.1941 - val_accuracy: 0.9167\n",
            "Epoch 129/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1470 - accuracy: 0.9688 - val_loss: 0.1822 - val_accuracy: 0.9167\n",
            "Epoch 130/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1482 - accuracy: 0.9792 - val_loss: 0.1726 - val_accuracy: 0.9167\n",
            "Epoch 131/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1454 - accuracy: 0.9792 - val_loss: 0.1839 - val_accuracy: 0.9167\n",
            "Epoch 132/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 0.9688 - val_loss: 0.1887 - val_accuracy: 0.9167\n",
            "Epoch 133/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1419 - accuracy: 0.9688 - val_loss: 0.1840 - val_accuracy: 0.9167\n",
            "Epoch 134/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1405 - accuracy: 0.9688 - val_loss: 0.1814 - val_accuracy: 0.9167\n",
            "Epoch 135/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1410 - accuracy: 0.9688 - val_loss: 0.1749 - val_accuracy: 0.9167\n",
            "Epoch 136/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1387 - accuracy: 0.9688 - val_loss: 0.1766 - val_accuracy: 0.9167\n",
            "Epoch 137/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1373 - accuracy: 0.9688 - val_loss: 0.1718 - val_accuracy: 0.9167\n",
            "Epoch 138/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1375 - accuracy: 0.9792 - val_loss: 0.1664 - val_accuracy: 0.9167\n",
            "Epoch 139/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1352 - accuracy: 0.9792 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 140/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1349 - accuracy: 0.9688 - val_loss: 0.1825 - val_accuracy: 0.9167\n",
            "Epoch 141/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1338 - accuracy: 0.9688 - val_loss: 0.1802 - val_accuracy: 0.9167\n",
            "Epoch 142/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1326 - accuracy: 0.9688 - val_loss: 0.1739 - val_accuracy: 0.9167\n",
            "Epoch 143/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1320 - accuracy: 0.9688 - val_loss: 0.1600 - val_accuracy: 0.9167\n",
            "Epoch 144/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.9792 - val_loss: 0.1568 - val_accuracy: 0.9167\n",
            "Epoch 145/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1298 - accuracy: 0.9792 - val_loss: 0.1657 - val_accuracy: 0.9167\n",
            "Epoch 146/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1284 - accuracy: 0.9792 - val_loss: 0.1719 - val_accuracy: 0.9167\n",
            "Epoch 147/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1277 - accuracy: 0.9688 - val_loss: 0.1710 - val_accuracy: 0.9167\n",
            "Epoch 148/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1275 - accuracy: 0.9688 - val_loss: 0.1610 - val_accuracy: 0.9167\n",
            "Epoch 149/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1257 - accuracy: 0.9792 - val_loss: 0.1608 - val_accuracy: 0.9167\n",
            "Epoch 150/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1248 - accuracy: 0.9792 - val_loss: 0.1594 - val_accuracy: 0.9167\n",
            "Epoch 151/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1240 - accuracy: 0.9792 - val_loss: 0.1585 - val_accuracy: 0.9167\n",
            "Epoch 152/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1231 - accuracy: 0.9792 - val_loss: 0.1597 - val_accuracy: 0.9167\n",
            "Epoch 153/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1223 - accuracy: 0.9792 - val_loss: 0.1595 - val_accuracy: 0.9167\n",
            "Epoch 154/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1226 - accuracy: 0.9792 - val_loss: 0.1569 - val_accuracy: 0.9167\n",
            "Epoch 155/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1217 - accuracy: 0.9688 - val_loss: 0.1644 - val_accuracy: 0.9167\n",
            "Epoch 156/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1202 - accuracy: 0.9688 - val_loss: 0.1606 - val_accuracy: 0.9167\n",
            "Epoch 157/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 0.9792 - val_loss: 0.1527 - val_accuracy: 0.9167\n",
            "Epoch 158/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1185 - accuracy: 0.9792 - val_loss: 0.1503 - val_accuracy: 0.9167\n",
            "Epoch 159/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1187 - accuracy: 0.9792 - val_loss: 0.1461 - val_accuracy: 0.9167\n",
            "Epoch 160/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1172 - accuracy: 0.9792 - val_loss: 0.1509 - val_accuracy: 0.9167\n",
            "Epoch 161/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1169 - accuracy: 0.9792 - val_loss: 0.1557 - val_accuracy: 0.9167\n",
            "Epoch 162/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1159 - accuracy: 0.9792 - val_loss: 0.1548 - val_accuracy: 0.9167\n",
            "Epoch 163/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1151 - accuracy: 0.9792 - val_loss: 0.1537 - val_accuracy: 0.9167\n",
            "Epoch 164/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1146 - accuracy: 0.9688 - val_loss: 0.1543 - val_accuracy: 0.9167\n",
            "Epoch 165/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 0.9792 - val_loss: 0.1416 - val_accuracy: 0.9167\n",
            "Epoch 166/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1151 - accuracy: 0.9792 - val_loss: 0.1544 - val_accuracy: 0.9167\n",
            "Epoch 167/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1134 - accuracy: 0.9688 - val_loss: 0.1560 - val_accuracy: 0.9167\n",
            "Epoch 168/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1123 - accuracy: 0.9792 - val_loss: 0.1461 - val_accuracy: 0.9167\n",
            "Epoch 169/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1118 - accuracy: 0.9792 - val_loss: 0.1403 - val_accuracy: 0.9167\n",
            "Epoch 170/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1112 - accuracy: 0.9792 - val_loss: 0.1394 - val_accuracy: 0.9167\n",
            "Epoch 171/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1101 - accuracy: 0.9792 - val_loss: 0.1466 - val_accuracy: 0.9167\n",
            "Epoch 172/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1105 - accuracy: 0.9792 - val_loss: 0.1568 - val_accuracy: 0.9167\n",
            "Epoch 173/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1098 - accuracy: 0.9688 - val_loss: 0.1544 - val_accuracy: 0.9167\n",
            "Epoch 174/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1086 - accuracy: 0.9792 - val_loss: 0.1411 - val_accuracy: 0.9167\n",
            "Epoch 175/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1103 - accuracy: 0.9792 - val_loss: 0.1313 - val_accuracy: 0.9167\n",
            "Epoch 176/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1078 - accuracy: 0.9896 - val_loss: 0.1362 - val_accuracy: 0.9167\n",
            "Epoch 177/250\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1061 - accuracy: 0.9792 - val_loss: 0.1439 - val_accuracy: 0.9167\n",
            "Epoch 178/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 0.9792 - val_loss: 0.1657 - val_accuracy: 0.9167\n",
            "Epoch 179/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1057 - accuracy: 0.9688 - val_loss: 0.1500 - val_accuracy: 0.9167\n",
            "Epoch 180/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.9792 - val_loss: 0.1284 - val_accuracy: 0.9167\n",
            "Epoch 181/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9896 - val_loss: 0.1325 - val_accuracy: 0.9167\n",
            "Epoch 182/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1034 - accuracy: 0.9792 - val_loss: 0.1413 - val_accuracy: 0.9167\n",
            "Epoch 183/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1027 - accuracy: 0.9792 - val_loss: 0.1445 - val_accuracy: 0.9167\n",
            "Epoch 184/250\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1017 - accuracy: 0.9792 - val_loss: 0.1408 - val_accuracy: 0.9167\n",
            "Epoch 185/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1006 - accuracy: 0.9792 - val_loss: 0.1310 - val_accuracy: 0.9167\n",
            "Epoch 186/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1026 - accuracy: 0.9792 - val_loss: 0.1225 - val_accuracy: 0.9167\n",
            "Epoch 187/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9896 - val_loss: 0.1253 - val_accuracy: 0.9167\n",
            "Epoch 188/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0993 - accuracy: 0.9896 - val_loss: 0.1388 - val_accuracy: 0.9167\n",
            "Epoch 189/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1036 - accuracy: 0.9688 - val_loss: 0.1643 - val_accuracy: 0.9167\n",
            "Epoch 190/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9688 - val_loss: 0.1615 - val_accuracy: 0.9167\n",
            "Epoch 191/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 0.1290 - val_accuracy: 0.9167\n",
            "Epoch 192/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.9896 - val_loss: 0.1079 - val_accuracy: 0.9167\n",
            "Epoch 193/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1002 - accuracy: 0.9896 - val_loss: 0.1166 - val_accuracy: 0.9167\n",
            "Epoch 194/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0968 - accuracy: 0.9896 - val_loss: 0.1327 - val_accuracy: 0.9167\n",
            "Epoch 195/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0969 - accuracy: 0.9792 - val_loss: 0.1476 - val_accuracy: 0.9167\n",
            "Epoch 196/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0976 - accuracy: 0.9688 - val_loss: 0.1489 - val_accuracy: 0.9167\n",
            "Epoch 197/250\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0968 - accuracy: 0.9792 - val_loss: 0.1382 - val_accuracy: 0.9167\n",
            "Epoch 198/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0977 - accuracy: 0.9896 - val_loss: 0.1181 - val_accuracy: 0.9167\n",
            "Epoch 199/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0959 - accuracy: 0.9896 - val_loss: 0.1172 - val_accuracy: 0.9167\n",
            "Epoch 200/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0963 - accuracy: 0.9792 - val_loss: 0.1341 - val_accuracy: 0.9167\n",
            "Epoch 201/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0949 - accuracy: 0.9792 - val_loss: 0.1430 - val_accuracy: 0.9167\n",
            "Epoch 202/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0943 - accuracy: 0.9792 - val_loss: 0.1377 - val_accuracy: 0.9167\n",
            "Epoch 203/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0937 - accuracy: 0.9792 - val_loss: 0.1260 - val_accuracy: 0.9167\n",
            "Epoch 204/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0930 - accuracy: 0.9792 - val_loss: 0.1220 - val_accuracy: 0.9167\n",
            "Epoch 205/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0931 - accuracy: 0.9896 - val_loss: 0.1156 - val_accuracy: 0.9167\n",
            "Epoch 206/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0932 - accuracy: 0.9896 - val_loss: 0.1197 - val_accuracy: 0.9167\n",
            "Epoch 207/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0934 - accuracy: 0.9896 - val_loss: 0.1212 - val_accuracy: 0.9167\n",
            "Epoch 208/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0938 - accuracy: 0.9792 - val_loss: 0.1413 - val_accuracy: 0.9167\n",
            "Epoch 209/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0923 - accuracy: 0.9792 - val_loss: 0.1413 - val_accuracy: 0.9167\n",
            "Epoch 210/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0920 - accuracy: 0.9792 - val_loss: 0.1259 - val_accuracy: 0.9167\n",
            "Epoch 211/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9792 - val_loss: 0.1234 - val_accuracy: 0.9167\n",
            "Epoch 212/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0917 - accuracy: 0.9896 - val_loss: 0.1130 - val_accuracy: 0.9167\n",
            "Epoch 213/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9896 - val_loss: 0.1190 - val_accuracy: 0.9167\n",
            "Epoch 214/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0896 - accuracy: 0.9896 - val_loss: 0.1265 - val_accuracy: 0.9167\n",
            "Epoch 215/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0902 - accuracy: 0.9792 - val_loss: 0.1338 - val_accuracy: 0.9167\n",
            "Epoch 216/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0902 - accuracy: 0.9792 - val_loss: 0.1315 - val_accuracy: 0.9167\n",
            "Epoch 217/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0891 - accuracy: 0.9792 - val_loss: 0.1255 - val_accuracy: 0.9167\n",
            "Epoch 218/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0901 - accuracy: 0.9792 - val_loss: 0.1121 - val_accuracy: 0.9167\n",
            "Epoch 219/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0892 - accuracy: 0.9896 - val_loss: 0.1139 - val_accuracy: 0.9167\n",
            "Epoch 220/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0897 - accuracy: 0.9896 - val_loss: 0.1297 - val_accuracy: 0.9167\n",
            "Epoch 221/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0886 - accuracy: 0.9792 - val_loss: 0.1242 - val_accuracy: 0.9167\n",
            "Epoch 222/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9792 - val_loss: 0.1251 - val_accuracy: 0.9167\n",
            "Epoch 223/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0878 - accuracy: 0.9792 - val_loss: 0.1200 - val_accuracy: 0.9167\n",
            "Epoch 224/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0873 - accuracy: 0.9896 - val_loss: 0.1193 - val_accuracy: 0.9167\n",
            "Epoch 225/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0886 - accuracy: 0.9792 - val_loss: 0.1312 - val_accuracy: 0.9167\n",
            "Epoch 226/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0874 - accuracy: 0.9792 - val_loss: 0.1303 - val_accuracy: 0.9167\n",
            "Epoch 227/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0889 - accuracy: 0.9792 - val_loss: 0.1101 - val_accuracy: 0.9167\n",
            "Epoch 228/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0869 - accuracy: 0.9896 - val_loss: 0.1105 - val_accuracy: 0.9167\n",
            "Epoch 229/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0872 - accuracy: 0.9792 - val_loss: 0.1251 - val_accuracy: 0.9167\n",
            "Epoch 230/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0859 - accuracy: 0.9792 - val_loss: 0.1279 - val_accuracy: 0.9167\n",
            "Epoch 231/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 0.1258 - val_accuracy: 0.9167\n",
            "Epoch 232/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0869 - accuracy: 0.9792 - val_loss: 0.1117 - val_accuracy: 0.9167\n",
            "Epoch 233/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0854 - accuracy: 0.9896 - val_loss: 0.1172 - val_accuracy: 0.9167\n",
            "Epoch 234/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0848 - accuracy: 0.9792 - val_loss: 0.1186 - val_accuracy: 0.9167\n",
            "Epoch 235/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0848 - accuracy: 0.9792 - val_loss: 0.1231 - val_accuracy: 0.9167\n",
            "Epoch 236/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0851 - accuracy: 0.9896 - val_loss: 0.1152 - val_accuracy: 0.9167\n",
            "Epoch 237/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0844 - accuracy: 0.9896 - val_loss: 0.1203 - val_accuracy: 0.9167\n",
            "Epoch 238/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9792 - val_loss: 0.1276 - val_accuracy: 0.9167\n",
            "Epoch 239/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0845 - accuracy: 0.9792 - val_loss: 0.1133 - val_accuracy: 0.9167\n",
            "Epoch 240/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0834 - accuracy: 0.9896 - val_loss: 0.1121 - val_accuracy: 0.9167\n",
            "Epoch 241/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9896 - val_loss: 0.1047 - val_accuracy: 0.9167\n",
            "Epoch 242/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9896 - val_loss: 0.1186 - val_accuracy: 0.9167\n",
            "Epoch 243/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 0.9792 - val_loss: 0.1355 - val_accuracy: 0.9167\n",
            "Epoch 244/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0835 - accuracy: 0.9792 - val_loss: 0.1266 - val_accuracy: 0.9167\n",
            "Epoch 245/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0823 - accuracy: 0.9792 - val_loss: 0.1170 - val_accuracy: 0.9167\n",
            "Epoch 246/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0824 - accuracy: 0.9896 - val_loss: 0.1079 - val_accuracy: 0.9167\n",
            "Epoch 247/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0842 - accuracy: 0.9896 - val_loss: 0.1012 - val_accuracy: 0.9167\n",
            "Epoch 248/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9896 - val_loss: 0.1171 - val_accuracy: 0.9167\n",
            "Epoch 249/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0815 - accuracy: 0.9792 - val_loss: 0.1229 - val_accuracy: 0.9167\n",
            "Epoch 250/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0818 - accuracy: 0.9792 - val_loss: 0.1268 - val_accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "soG4_9zOqMXj",
        "outputId": "808e4a82-7e74-4ac7-db2f-5bd097fa3909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56fa45d4-a658-4e1d-ad2f-479f842ff20b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.334653</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>1.438641</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.179970</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>1.230915</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.077336</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>1.091671</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.020077</td>\n",
              "      <td>0.447917</td>\n",
              "      <td>1.005109</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.981762</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.957405</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>0.082360</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.107912</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>0.084176</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.101225</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>0.083102</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.117144</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>0.081515</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.122935</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>0.081768</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.126784</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56fa45d4-a658-4e1d-ad2f-479f842ff20b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56fa45d4-a658-4e1d-ad2f-479f842ff20b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56fa45d4-a658-4e1d-ad2f-479f842ff20b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0    1.334653  0.343750  1.438641      0.250000      0\n",
              "1    1.179970  0.343750  1.230915      0.250000      1\n",
              "2    1.077336  0.291667  1.091671      0.291667      2\n",
              "3    1.020077  0.447917  1.005109      0.500000      3\n",
              "4    0.981762  0.583333  0.957405      0.666667      4\n",
              "..        ...       ...       ...           ...    ...\n",
              "245  0.082360  0.989583  0.107912      0.916667    245\n",
              "246  0.084176  0.989583  0.101225      0.916667    246\n",
              "247  0.083102  0.989583  0.117144      0.916667    247\n",
              "248  0.081515  0.979167  0.122935      0.916667    248\n",
              "249  0.081768  0.979167  0.126784      0.916667    249\n",
              "\n",
              "[250 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk_I4Hdcrgmb",
        "outputId": "98f78381-636c-468c-fcd4-9935878076aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0582 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test[:1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPw8EONgrqS5",
        "outputId": "7b26d4ba-3573-4e45-e07d-3fdae9693ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.9803842e-05, 1.3141114e-03, 9.9861610e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y79cN7wxrut7",
        "outputId": "c0fb582f-9952-452e-9135-058e5e6528c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_train[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUI7sW2Er1j1",
        "outputId": "5766c500-6c7e-4270-b203-d0a453025f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.8197147e-04, 3.8879495e-02, 9.6083850e-01],\n",
              "       [4.6987939e-03, 5.4483241e-01, 4.5046875e-01],\n",
              "       [9.9795097e-01, 2.0343515e-03, 1.4764793e-05],\n",
              "       [1.5758182e-03, 2.2441459e-01, 7.7400964e-01],\n",
              "       [4.2417938e-05, 1.4951127e-03, 9.9846244e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sepal_length = 4.8\n",
        "sepal_width = 3.3\n",
        "petal_length = 1.4\n",
        "petal_width = 0.2\n",
        "\n",
        "model.predict(\n",
        "    np.array([\n",
        "        [sepal_length, sepal_width, petal_length, petal_width]\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bykr59_Rspz8",
        "outputId": "12d04fdc-0159-450d-85b7-0b199223a39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9707103e-01, 2.9003858e-03, 2.8579640e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EJERCICIO 2**\n",
        "\n",
        "Para el modelo entrenado en el ejercicio anterior, para train y validation:\n",
        "\n",
        "*  representar la evolución de la función de coste\n",
        "*  representar la evolución del accuracy \n",
        "\n",
        "\n",
        "Comentar los resultados obtenidos"
      ],
      "metadata": {
        "id": "8rLss47l8USx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Categorical Crossentropy')\n",
        "\n",
        "plt.plot(hist['epoch'], hist['loss'],\n",
        "       label='Train Error')\n",
        "plt.plot(hist['epoch'], hist['val_loss'],\n",
        "       label = 'Val Error')\n",
        "\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fSZXcelz8YVD",
        "outputId": "909276c6-5ae7-437b-9a07-adcc5787a99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 3¶**\n",
        "\n",
        "Se deberá crear un modelo consistente en una red sencilla compuesta por:\n",
        "\n",
        "*  Entrada de datos de dimensión (2,).\n",
        "*  Una unica capa oculta densa con 2 neuronas que implemente la función de activación \"linear\". Es importante no olvidar la función de activación mencionada.\n",
        "*   Una capa densa a la salida con una única neurona que implemente la función de activación \"li\n",
        "\n",
        "El esquema de la red sería el siguiente:\n",
        "\n",
        "simple_net\n",
        "\n",
        "La construcción del modelo puede realizarse de manera análoga a la de los apartados \"definición del modelo\" o \"proceso completo\".\n",
        "\n",
        "No es necesario ni compilar ni entrenar el modelo. Las neuronas tendrán pesos y bias asignados de manera aleatoria."
      ],
      "metadata": {
        "id": "6pBIfuluKpiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(2,), name='input_layer')\n",
        "l_1 = layers.Dense(2, activation='relu', name='layer_1')(inputs)   \n",
        "outputs = layers.Dense(1, name='output_layer',activation='relu')(l_1)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5ZkwVnidA1r",
        "outputId": "da4c66b0-c9e7-45bf-c87e-1d43e20d690a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"example_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 2)]               0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 2)                 6         \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EJERCICIO 4**\n",
        "\n",
        "\n",
        "En el apartado de definición de modelos con Keras se presentó la manera de obtener información sobre las capas y los valores de los pesos y biases asignados (de manera aleatoria) a cada neurona.\n",
        "\n",
        "Para el modelo construido en el ejercicio anterior, para la capa oculta y la capa de salida, devuelva los pesos y los bias interpretando los valores.\n",
        "\n",
        "Para cada capa será suficiente con decir:\n",
        "*   Para los pesos, decir qué valor se corresponde con qué entrada-neurona.\n",
        "*   Para los biases, decir qué valor se corresponde con qué neurona"
      ],
      "metadata": {
        "id": "hfZKNCwPNqyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = model.layers[1].get_weights()\n",
        "print(\"Pesos de la primera capa oculta:\\n{}\".format(weights))\n",
        "print(\"Biases de la primera capa oculta:\\n{}\".format(weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPcDRg1sa4eo",
        "outputId": "c3512370-aa12-485b-c151-997c041062c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos de la primera capa oculta:\n",
            "[[-0.03132772 -0.43973184]\n",
            " [ 0.90066063 -1.1952446 ]]\n",
            "Biases de la primera capa oculta:\n",
            "[[-0.03132772 -0.43973184]\n",
            " [ 0.90066063 -1.1952446 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 5**"
      ],
      "metadata": {
        "id": "-lW6VlSzbwdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([\n",
        "    [0, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "AaTXV4-GcDqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "idACm313cT0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}