{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "victoriadelpozo-a11-mod2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBg/oIVGDVSHd3qMVM0H0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriadelpozo/RedesNeuronales/blob/main/victoriadelpozo_a11_mod2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 1**\n",
        "\n",
        "En el ejemplo en el que se visualizan los resultados del modelo entrenado sin realizar ninguna regularización, se podía observar cómo el modelo sobreajustaba claramente a los datos de entrenamiento.\n",
        "\n",
        "De manera justificada, y en función de los valores mostrados en las gráficas, ¿a partir de qué época puede decirse que es claro el efecto del sobreajuste?"
      ],
      "metadata": {
        "id": "K3eCn_hM8naQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Son el característico cuando un modelo presenta Overfitting.\n",
        "Por un lado la Accuracyde los datos de entrenamiento aumenta linealmente con las epochs, \n",
        "hasta alcanzar casi el 100%, mientras que la Accuracyde los datos de validación se detiene alrededor del 75% y a partir de aquí se mantiene constante a lo largo de las epochs. \n",
        "La linea de error de los datos de validación alcanza su mínimo después de pocos epoch (10) luego empieza a subir, mientras que la Lossde los datos de entrenamiento disminuye linealmente hasta llegar a casi 0 donde se mantiene."
      ],
      "metadata": {
        "id": "3kkFbjviFgsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 2**\n",
        "\n",
        "En el apartado donde se aplica dropout en dos de las capas ocultas se visualiza la evolución de los valores de la función de pérdida y del accuracy.\n",
        "\n",
        "Comente de manera justificada si aprecia diferencias entre los resultados obtenidos aplicando dropout y los obtenidos en el primer ejemplo."
      ],
      "metadata": {
        "id": "quzVDtIiGB1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Son el característico cuando un modelo presenta Overfitting.\n",
        "Por un lado la Accuracyde los datos de entrenamiento aumenta linealmente con las epochs, \n",
        "hasta alcanzar casi el 100%, mientras que la Accuracyde los datos de validación se detiene alrededor del 75% y a partir de aquí se mantiene constante a lo largo de las epochs. \n",
        "La linea de error de los datos de validación alcanza su mínimo después de pocos epoch (10) luego empieza a subir, mientras que la Lossde los datos de entrenamiento disminuye linealmente hasta llegar a casi 0 donde se mantiene.\n",
        "Reduce el sobreajuste"
      ],
      "metadata": {
        "id": "AS3qHVxaHhRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 3**\n",
        "\n",
        "De nuevo, tomando como referencia el ejemplo aplicando dropout, en el espacio destinado para ello en la Respuesta 3:\n",
        "\n",
        "construya un modelo igual que el del ejemplo y, repitiendo el entramiento, varíe el valor del ratio de dropout en ambas capas de la siguiente manera:\n",
        "\n",
        "1.   un valor de 0.9\n",
        "2.   un valor de 0.1\n",
        "\n",
        "construya un modelo igual que el del ejemplo y, repitiendo el entramiento, incluya dropout en la tercera capa oculta con el mismo ratio de dropout que las otras dos capas ocultas.\n",
        "\n",
        "Comente de manera justificada los resultados obtenidos."
      ],
      "metadata": {
        "id": "2iezReegbTnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "#data = 'r\"C:\\Users\\Victoria\\Desktop\\Master Data Science\\Tecnicas Avanzadas de IA\\dont-overfit-ii\"'\n",
        "#train_set = 'train.csv'\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "vqinPdradwwY",
        "outputId": "a1ca7ce1-9692-45ba-9e7e-873b98860e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 302)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9f97eac-7425-4432-8585-bb37b1731977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.067</td>\n",
              "      <td>-1.114</td>\n",
              "      <td>-0.616</td>\n",
              "      <td>0.376</td>\n",
              "      <td>1.090</td>\n",
              "      <td>0.467</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>0.460</td>\n",
              "      <td>-0.443</td>\n",
              "      <td>-0.338</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-2.177</td>\n",
              "      <td>-0.326</td>\n",
              "      <td>0.340</td>\n",
              "      <td>1.174</td>\n",
              "      <td>-0.245</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.336</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>0.403</td>\n",
              "      <td>-0.605</td>\n",
              "      <td>-0.280</td>\n",
              "      <td>-1.618</td>\n",
              "      <td>0.878</td>\n",
              "      <td>-0.272</td>\n",
              "      <td>0.870</td>\n",
              "      <td>2.171</td>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.477</td>\n",
              "      <td>-2.092</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.621</td>\n",
              "      <td>-2.810</td>\n",
              "      <td>1.029</td>\n",
              "      <td>-0.736</td>\n",
              "      <td>0.582</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.848</td>\n",
              "      <td>-1.781</td>\n",
              "      <td>0.254</td>\n",
              "      <td>-0.515</td>\n",
              "      <td>0.234</td>\n",
              "      <td>0.296</td>\n",
              "      <td>-1.774</td>\n",
              "      <td>2.032</td>\n",
              "      <td>-0.442</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>1.393</td>\n",
              "      <td>-0.494</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>1.874</td>\n",
              "      <td>1.463</td>\n",
              "      <td>-1.397</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.557</td>\n",
              "      <td>-0.522</td>\n",
              "      <td>-0.503</td>\n",
              "      <td>-0.541</td>\n",
              "      <td>1.393</td>\n",
              "      <td>0.506</td>\n",
              "      <td>-1.420</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>-1.833</td>\n",
              "      <td>0.220</td>\n",
              "      <td>-0.339</td>\n",
              "      <td>0.254</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.436</td>\n",
              "      <td>0.958</td>\n",
              "      <td>-0.824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.271</td>\n",
              "      <td>1.716</td>\n",
              "      <td>1.096</td>\n",
              "      <td>1.731</td>\n",
              "      <td>-0.197</td>\n",
              "      <td>1.904</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>0.557</td>\n",
              "      <td>1.202</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.424</td>\n",
              "      <td>-1.572</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>-1.483</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>-1.490</td>\n",
              "      <td>0.179</td>\n",
              "      <td>-0.524</td>\n",
              "      <td>0.250</td>\n",
              "      <td>2.462</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>-2.370</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.106</td>\n",
              "      <td>-0.145</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-1.045</td>\n",
              "      <td>1.335</td>\n",
              "      <td>1.254</td>\n",
              "      <td>-0.811</td>\n",
              "      <td>1.812</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.627</td>\n",
              "      <td>-1.472</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.052</td>\n",
              "      <td>0.322</td>\n",
              "      <td>-0.222</td>\n",
              "      <td>1.168</td>\n",
              "      <td>0.931</td>\n",
              "      <td>-0.203</td>\n",
              "      <td>0.321</td>\n",
              "      <td>0.761</td>\n",
              "      <td>1.752</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-3.029</td>\n",
              "      <td>-0.578</td>\n",
              "      <td>-0.260</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>1.097</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.578</td>\n",
              "      <td>-0.544</td>\n",
              "      <td>0.441</td>\n",
              "      <td>-0.524</td>\n",
              "      <td>-1.474</td>\n",
              "      <td>-0.090</td>\n",
              "      <td>-0.607</td>\n",
              "      <td>-0.765</td>\n",
              "      <td>-0.735</td>\n",
              "      <td>-1.158</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.856</td>\n",
              "      <td>-1.506</td>\n",
              "      <td>0.462</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-1.932</td>\n",
              "      <td>-0.343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099</td>\n",
              "      <td>1.390</td>\n",
              "      <td>-0.732</td>\n",
              "      <td>-1.065</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.081</td>\n",
              "      <td>-1.450</td>\n",
              "      <td>0.317</td>\n",
              "      <td>-0.624</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.665</td>\n",
              "      <td>1.905</td>\n",
              "      <td>0.376</td>\n",
              "      <td>-1.373</td>\n",
              "      <td>1.587</td>\n",
              "      <td>1.464</td>\n",
              "      <td>-1.550</td>\n",
              "      <td>-0.512</td>\n",
              "      <td>0.508</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.643</td>\n",
              "      <td>-1.371</td>\n",
              "      <td>1.553</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-0.465</td>\n",
              "      <td>-1.252</td>\n",
              "      <td>0.443</td>\n",
              "      <td>2.205</td>\n",
              "      <td>-1.266</td>\n",
              "      <td>-0.739</td>\n",
              "      <td>0.827</td>\n",
              "      <td>-1.306</td>\n",
              "      <td>0.274</td>\n",
              "      <td>-1.573</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.610</td>\n",
              "      <td>-0.801</td>\n",
              "      <td>1.557</td>\n",
              "      <td>0.628</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>-0.573</td>\n",
              "      <td>0.507</td>\n",
              "      <td>-1.229</td>\n",
              "      <td>0.313</td>\n",
              "      <td>1.446</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>1.147</td>\n",
              "      <td>-0.623</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>1.456</td>\n",
              "      <td>-0.932</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.671</td>\n",
              "      <td>-0.596</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>0.966</td>\n",
              "      <td>-0.167</td>\n",
              "      <td>0.530</td>\n",
              "      <td>-1.493</td>\n",
              "      <td>-0.917</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.258</td>\n",
              "      <td>-0.405</td>\n",
              "      <td>-0.859</td>\n",
              "      <td>-1.311</td>\n",
              "      <td>0.799</td>\n",
              "      <td>-1.001</td>\n",
              "      <td>1.544</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-0.309</td>\n",
              "      <td>-0.339</td>\n",
              "      <td>-0.148</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.989</td>\n",
              "      <td>-0.916</td>\n",
              "      <td>-1.343</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.543</td>\n",
              "      <td>0.636</td>\n",
              "      <td>1.127</td>\n",
              "      <td>0.189</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>0.760</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-2.048</td>\n",
              "      <td>-0.996</td>\n",
              "      <td>-0.361</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.595</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.483</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>-0.551</td>\n",
              "      <td>-1.736</td>\n",
              "      <td>-2.014</td>\n",
              "      <td>0.636</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>-0.767</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>0.815</td>\n",
              "      <td>1.696</td>\n",
              "      <td>-0.436</td>\n",
              "      <td>-1.777</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.978</td>\n",
              "      <td>1.299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011</td>\n",
              "      <td>1.137</td>\n",
              "      <td>0.499</td>\n",
              "      <td>-0.262</td>\n",
              "      <td>-1.484</td>\n",
              "      <td>0.216</td>\n",
              "      <td>-2.536</td>\n",
              "      <td>0.191</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>1.387</td>\n",
              "      <td>-1.617</td>\n",
              "      <td>-0.662</td>\n",
              "      <td>-2.288</td>\n",
              "      <td>-1.130</td>\n",
              "      <td>0.651</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>0.686</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>1.734</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>0.514</td>\n",
              "      <td>-0.506</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.382</td>\n",
              "      <td>-1.119</td>\n",
              "      <td>1.695</td>\n",
              "      <td>-0.775</td>\n",
              "      <td>-1.428</td>\n",
              "      <td>0.231</td>\n",
              "      <td>-0.780</td>\n",
              "      <td>-1.370</td>\n",
              "      <td>1.093</td>\n",
              "      <td>0.596</td>\n",
              "      <td>-0.589</td>\n",
              "      <td>-0.649</td>\n",
              "      <td>-0.163</td>\n",
              "      <td>-0.958</td>\n",
              "      <td>-1.081</td>\n",
              "      <td>0.805</td>\n",
              "      <td>3.401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811</td>\n",
              "      <td>-1.509</td>\n",
              "      <td>0.522</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>-0.959</td>\n",
              "      <td>0.334</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>-0.656</td>\n",
              "      <td>-0.499</td>\n",
              "      <td>-0.653</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.654</td>\n",
              "      <td>-0.697</td>\n",
              "      <td>-1.175</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.402</td>\n",
              "      <td>-1.037</td>\n",
              "      <td>1.081</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.144</td>\n",
              "      <td>1.720</td>\n",
              "      <td>-1.980</td>\n",
              "      <td>-0.741</td>\n",
              "      <td>-1.493</td>\n",
              "      <td>-0.860</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.133</td>\n",
              "      <td>1.084</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>0.198</td>\n",
              "      <td>1.144</td>\n",
              "      <td>1.123</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-2.933</td>\n",
              "      <td>...</td>\n",
              "      <td>0.285</td>\n",
              "      <td>-0.464</td>\n",
              "      <td>1.427</td>\n",
              "      <td>0.554</td>\n",
              "      <td>-0.131</td>\n",
              "      <td>-1.425</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.413</td>\n",
              "      <td>-0.231</td>\n",
              "      <td>1.570</td>\n",
              "      <td>-0.714</td>\n",
              "      <td>0.385</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>0.150</td>\n",
              "      <td>-0.228</td>\n",
              "      <td>0.144</td>\n",
              "      <td>-1.537</td>\n",
              "      <td>0.664</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.424</td>\n",
              "      <td>0.926</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.415</td>\n",
              "      <td>0.299</td>\n",
              "      <td>-1.227</td>\n",
              "      <td>-2.578</td>\n",
              "      <td>0.600</td>\n",
              "      <td>2.167</td>\n",
              "      <td>-0.755</td>\n",
              "      <td>-1.265</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>0.718</td>\n",
              "      <td>-1.017</td>\n",
              "      <td>1.249</td>\n",
              "      <td>-0.596</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>1.751</td>\n",
              "      <td>1.442</td>\n",
              "      <td>-0.393</td>\n",
              "      <td>-0.643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9f97eac-7425-4432-8585-bb37b1731977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9f97eac-7425-4432-8585-bb37b1731977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9f97eac-7425-4432-8585-bb37b1731977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  target      0      1      2  ...    295    296    297    298    299\n",
              "0   0     1.0 -1.067 -1.114 -0.616  ...  0.125  0.347  0.436  0.958 -0.824\n",
              "1   1     0.0 -0.831  0.271  1.716  ... -1.506  0.462 -0.029 -1.932 -0.343\n",
              "2   2     0.0  0.099  1.390 -0.732  ... -0.309 -0.339 -0.148 -0.646  0.725\n",
              "3   3     1.0 -0.989 -0.916 -1.343  ... -0.163 -0.958 -1.081  0.805  3.401\n",
              "4   4     0.0  0.811 -1.509  0.522  ... -0.445  1.751  1.442 -0.393 -0.643\n",
              "\n",
              "[5 rows x 302 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "9Versjiy4Oif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(df_train['target']))\n",
        "df_train.pop('id')\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "r6b2QhoMSJO5",
        "outputId": "a02fa630-7220-4ae9-e7ab-498d523c819c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.0, 1.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cef96ebe-9a90-4eb8-ad22-758ba069c4f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.067</td>\n",
              "      <td>-1.114</td>\n",
              "      <td>-0.616</td>\n",
              "      <td>0.376</td>\n",
              "      <td>1.090</td>\n",
              "      <td>0.467</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>0.460</td>\n",
              "      <td>-0.443</td>\n",
              "      <td>-0.338</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-2.177</td>\n",
              "      <td>-0.326</td>\n",
              "      <td>0.340</td>\n",
              "      <td>1.174</td>\n",
              "      <td>-0.245</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.336</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>0.403</td>\n",
              "      <td>-0.605</td>\n",
              "      <td>-0.280</td>\n",
              "      <td>-1.618</td>\n",
              "      <td>0.878</td>\n",
              "      <td>-0.272</td>\n",
              "      <td>0.870</td>\n",
              "      <td>2.171</td>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.477</td>\n",
              "      <td>-2.092</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.621</td>\n",
              "      <td>-2.810</td>\n",
              "      <td>1.029</td>\n",
              "      <td>-0.736</td>\n",
              "      <td>0.582</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.493</td>\n",
              "      <td>1.359</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.848</td>\n",
              "      <td>-1.781</td>\n",
              "      <td>0.254</td>\n",
              "      <td>-0.515</td>\n",
              "      <td>0.234</td>\n",
              "      <td>0.296</td>\n",
              "      <td>-1.774</td>\n",
              "      <td>2.032</td>\n",
              "      <td>-0.442</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>1.393</td>\n",
              "      <td>-0.494</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>1.874</td>\n",
              "      <td>1.463</td>\n",
              "      <td>-1.397</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.557</td>\n",
              "      <td>-0.522</td>\n",
              "      <td>-0.503</td>\n",
              "      <td>-0.541</td>\n",
              "      <td>1.393</td>\n",
              "      <td>0.506</td>\n",
              "      <td>-1.420</td>\n",
              "      <td>-0.123</td>\n",
              "      <td>-1.833</td>\n",
              "      <td>0.220</td>\n",
              "      <td>-0.339</td>\n",
              "      <td>0.254</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.436</td>\n",
              "      <td>0.958</td>\n",
              "      <td>-0.824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.271</td>\n",
              "      <td>1.716</td>\n",
              "      <td>1.096</td>\n",
              "      <td>1.731</td>\n",
              "      <td>-0.197</td>\n",
              "      <td>1.904</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>0.557</td>\n",
              "      <td>1.202</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.424</td>\n",
              "      <td>-1.572</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>-1.483</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>-1.490</td>\n",
              "      <td>0.179</td>\n",
              "      <td>-0.524</td>\n",
              "      <td>0.250</td>\n",
              "      <td>2.462</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>-2.370</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.106</td>\n",
              "      <td>-0.145</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-1.045</td>\n",
              "      <td>1.335</td>\n",
              "      <td>1.254</td>\n",
              "      <td>-0.811</td>\n",
              "      <td>1.812</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>1.125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.627</td>\n",
              "      <td>-1.472</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.052</td>\n",
              "      <td>0.322</td>\n",
              "      <td>-0.222</td>\n",
              "      <td>1.168</td>\n",
              "      <td>0.931</td>\n",
              "      <td>-0.203</td>\n",
              "      <td>0.321</td>\n",
              "      <td>0.761</td>\n",
              "      <td>1.752</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-3.029</td>\n",
              "      <td>-0.578</td>\n",
              "      <td>-0.260</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>1.097</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.578</td>\n",
              "      <td>-0.544</td>\n",
              "      <td>0.441</td>\n",
              "      <td>-0.524</td>\n",
              "      <td>-1.474</td>\n",
              "      <td>-0.090</td>\n",
              "      <td>-0.607</td>\n",
              "      <td>-0.765</td>\n",
              "      <td>-0.735</td>\n",
              "      <td>-1.158</td>\n",
              "      <td>2.554</td>\n",
              "      <td>0.856</td>\n",
              "      <td>-1.506</td>\n",
              "      <td>0.462</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>-1.932</td>\n",
              "      <td>-0.343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099</td>\n",
              "      <td>1.390</td>\n",
              "      <td>-0.732</td>\n",
              "      <td>-1.065</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.081</td>\n",
              "      <td>-1.450</td>\n",
              "      <td>0.317</td>\n",
              "      <td>-0.624</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.665</td>\n",
              "      <td>1.905</td>\n",
              "      <td>0.376</td>\n",
              "      <td>-1.373</td>\n",
              "      <td>1.587</td>\n",
              "      <td>1.464</td>\n",
              "      <td>-1.550</td>\n",
              "      <td>-0.512</td>\n",
              "      <td>0.508</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.643</td>\n",
              "      <td>-1.371</td>\n",
              "      <td>1.553</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-0.465</td>\n",
              "      <td>-1.252</td>\n",
              "      <td>0.443</td>\n",
              "      <td>2.205</td>\n",
              "      <td>-1.266</td>\n",
              "      <td>-0.739</td>\n",
              "      <td>0.827</td>\n",
              "      <td>-1.306</td>\n",
              "      <td>0.274</td>\n",
              "      <td>-1.573</td>\n",
              "      <td>-2.011</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.610</td>\n",
              "      <td>-0.801</td>\n",
              "      <td>1.557</td>\n",
              "      <td>0.628</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>-0.573</td>\n",
              "      <td>0.507</td>\n",
              "      <td>-1.229</td>\n",
              "      <td>0.313</td>\n",
              "      <td>1.446</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>1.147</td>\n",
              "      <td>-0.623</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>1.456</td>\n",
              "      <td>-0.932</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.671</td>\n",
              "      <td>-0.596</td>\n",
              "      <td>-0.135</td>\n",
              "      <td>0.966</td>\n",
              "      <td>-0.167</td>\n",
              "      <td>0.530</td>\n",
              "      <td>-1.493</td>\n",
              "      <td>-0.917</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.258</td>\n",
              "      <td>-0.405</td>\n",
              "      <td>-0.859</td>\n",
              "      <td>-1.311</td>\n",
              "      <td>0.799</td>\n",
              "      <td>-1.001</td>\n",
              "      <td>1.544</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-0.309</td>\n",
              "      <td>-0.339</td>\n",
              "      <td>-0.148</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.989</td>\n",
              "      <td>-0.916</td>\n",
              "      <td>-1.343</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.543</td>\n",
              "      <td>0.636</td>\n",
              "      <td>1.127</td>\n",
              "      <td>0.189</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>0.760</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-2.048</td>\n",
              "      <td>-0.996</td>\n",
              "      <td>-0.361</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.595</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.483</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>-0.551</td>\n",
              "      <td>-1.736</td>\n",
              "      <td>-2.014</td>\n",
              "      <td>0.636</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>-0.767</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>0.815</td>\n",
              "      <td>1.696</td>\n",
              "      <td>-0.436</td>\n",
              "      <td>-1.777</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.978</td>\n",
              "      <td>1.299</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011</td>\n",
              "      <td>1.137</td>\n",
              "      <td>0.499</td>\n",
              "      <td>-0.262</td>\n",
              "      <td>-1.484</td>\n",
              "      <td>0.216</td>\n",
              "      <td>-2.536</td>\n",
              "      <td>0.191</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>1.387</td>\n",
              "      <td>-1.617</td>\n",
              "      <td>-0.662</td>\n",
              "      <td>-2.288</td>\n",
              "      <td>-1.130</td>\n",
              "      <td>0.651</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>0.686</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>1.734</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>0.514</td>\n",
              "      <td>-0.506</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.382</td>\n",
              "      <td>-1.119</td>\n",
              "      <td>1.695</td>\n",
              "      <td>-0.775</td>\n",
              "      <td>-1.428</td>\n",
              "      <td>0.231</td>\n",
              "      <td>-0.780</td>\n",
              "      <td>-1.370</td>\n",
              "      <td>1.093</td>\n",
              "      <td>0.596</td>\n",
              "      <td>-0.589</td>\n",
              "      <td>-0.649</td>\n",
              "      <td>-0.163</td>\n",
              "      <td>-0.958</td>\n",
              "      <td>-1.081</td>\n",
              "      <td>0.805</td>\n",
              "      <td>3.401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811</td>\n",
              "      <td>-1.509</td>\n",
              "      <td>0.522</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>-0.959</td>\n",
              "      <td>0.334</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>-0.656</td>\n",
              "      <td>-0.499</td>\n",
              "      <td>-0.653</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.654</td>\n",
              "      <td>-0.697</td>\n",
              "      <td>-1.175</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.402</td>\n",
              "      <td>-1.037</td>\n",
              "      <td>1.081</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.144</td>\n",
              "      <td>1.720</td>\n",
              "      <td>-1.980</td>\n",
              "      <td>-0.741</td>\n",
              "      <td>-1.493</td>\n",
              "      <td>-0.860</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.133</td>\n",
              "      <td>1.084</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>0.198</td>\n",
              "      <td>1.144</td>\n",
              "      <td>1.123</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-2.933</td>\n",
              "      <td>0.831</td>\n",
              "      <td>...</td>\n",
              "      <td>0.285</td>\n",
              "      <td>-0.464</td>\n",
              "      <td>1.427</td>\n",
              "      <td>0.554</td>\n",
              "      <td>-0.131</td>\n",
              "      <td>-1.425</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.413</td>\n",
              "      <td>-0.231</td>\n",
              "      <td>1.570</td>\n",
              "      <td>-0.714</td>\n",
              "      <td>0.385</td>\n",
              "      <td>-0.072</td>\n",
              "      <td>0.150</td>\n",
              "      <td>-0.228</td>\n",
              "      <td>0.144</td>\n",
              "      <td>-1.537</td>\n",
              "      <td>0.664</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.424</td>\n",
              "      <td>0.926</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-0.415</td>\n",
              "      <td>0.299</td>\n",
              "      <td>-1.227</td>\n",
              "      <td>-2.578</td>\n",
              "      <td>0.600</td>\n",
              "      <td>2.167</td>\n",
              "      <td>-0.755</td>\n",
              "      <td>-1.265</td>\n",
              "      <td>-0.178</td>\n",
              "      <td>0.718</td>\n",
              "      <td>-1.017</td>\n",
              "      <td>1.249</td>\n",
              "      <td>-0.596</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>1.751</td>\n",
              "      <td>1.442</td>\n",
              "      <td>-0.393</td>\n",
              "      <td>-0.643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 301 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cef96ebe-9a90-4eb8-ad22-758ba069c4f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cef96ebe-9a90-4eb8-ad22-758ba069c4f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cef96ebe-9a90-4eb8-ad22-758ba069c4f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   target      0      1      2      3  ...    295    296    297    298    299\n",
              "0     1.0 -1.067 -1.114 -0.616  0.376  ...  0.125  0.347  0.436  0.958 -0.824\n",
              "1     0.0 -0.831  0.271  1.716  1.096  ... -1.506  0.462 -0.029 -1.932 -0.343\n",
              "2     0.0  0.099  1.390 -0.732 -1.065  ... -0.309 -0.339 -0.148 -0.646  0.725\n",
              "3     1.0 -0.989 -0.916 -1.343  0.145  ... -0.163 -0.958 -1.081  0.805  3.401\n",
              "4     0.0  0.811 -1.509  0.522 -0.360  ... -0.445  1.751  1.442 -0.393 -0.643\n",
              "\n",
              "[5 rows x 301 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "mEswK2XQN256"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(300,), name='input_layer')  # entrada\n",
        "\n",
        "l_1 = layers.Dense(128, activation='relu', name='layer_1')(inputs)  # capa oculta 1\n",
        "l_1 = keras.layers.Dropout(0.9, name='dropout_l1')(l_1)  # dropout sobre la capa oculta 1\n",
        "l_2 = layers.Dense(64, activation='relu', name='layer_2')(l_1)  # capa oculta 2\n",
        "l_2 = keras.layers.Dropout(0.1, name='dropout_l2')(l_2)  # dropout sobre la capa oculta 2\n",
        "l_3 = layers.Dense(32, activation='relu', name='layer_3')(l_2)  # capa oculta 3\n",
        "\n",
        "outputs = layers.Dense(1, activation='sigmoid', name='output_layer')(l_3)  # salida\n",
        "\n",
        "model_dropout = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_dropout')"
      ],
      "metadata": {
        "id": "0ozfI-jibXPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dropout.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyeXKbBXOca_",
        "outputId": "47fa4f57-57f9-4435-f13c-5ff28a566a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dont_overfit_model_dropout\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 300)]             0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 128)               38528     \n",
            "                                                                 \n",
            " dropout_l1 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_l2 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " layer_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,897\n",
            "Trainable params: 48,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dropout.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "df_train.iloc[:, 1:].values\n",
        "x = df_train.iloc[:, 1:].values\n",
        "y = df_train.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "qx7xUov4SWox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(300,), name='input_layer')  # entrada\n",
        "\n",
        "l_1 = layers.Dense(128, activation='relu', name='layer_1')(inputs)  # capa oculta 1\n",
        "l_1 = keras.layers.Dropout(0.1, name='dropout_l1')(l_1)  # dropout sobre la capa oculta 1\n",
        "l_2 = layers.Dense(64, activation='relu', name='layer_2')(l_1)  # capa oculta 2\n",
        "l_2 = keras.layers.Dropout(0.1, name='dropout_l2')(l_2)  # dropout sobre la capa oculta 2\n",
        "l_3 = layers.Dense(32, activation='relu', name='layer_3')(l_2)  # capa oculta 3\n",
        "l_3 = keras.layers.Dropout(0.1, name='dropout_l3')(l_3)  # dropout sobre la capa oculta 2\n",
        "outputs = layers.Dense(1, activation='sigmoid', name='output_layer')(l_3)  # salida\n",
        "\n",
        "model_dropout_1 = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_dropout')"
      ],
      "metadata": {
        "id": "klAx5mr1deSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dropout_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePgZv-3udvEn",
        "outputId": "6942565e-055d-4bb3-aac8-995b5cd864b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dont_overfit_model_dropout\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 300)]             0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 128)               38528     \n",
            "                                                                 \n",
            " dropout_l1 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_l2 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " layer_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_l3 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,897\n",
            "Trainable params: 48,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 4**\n",
        "\n",
        "En el ejercicio donde se presenta y aplica early stopping en el entrenamiento del modelo puede verse como el proceso se detiene tras pasar solo algunas épocas.\n",
        "\n",
        "Se pide que el alumno:\n",
        "\n",
        "\n",
        "*   compare los resultados obtenidos con el primer modelo de ejemplo\n",
        "*   reproduzca el entrenamiento analizando los resultados cuando:\n",
        "  \n",
        "  -se selecciona val_accuracy en lugar de val_loss como variable a monitorizar\n",
        "  \n",
        "  -se modifica el valor del parámetro patience por un número mayor de épocas\n",
        "*   interprete y analice los resultados obtenidos\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pyyxedZwOvwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accurancy',  # nos interesa analizar el valor de la función de pérdida para el set de validación\n",
        "    patience=8,  # si durante 8 épocas no existe mejora en `val_loss` se detendrá la ejecución\n",
        "    mode='auto'  # por defecto se inferirá el sentido de la mejora\n",
        ")"
      ],
      "metadata": {
        "id": "cvOKPw9LQE7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(300,), name='input_layer')  # entrada\n",
        "\n",
        "l_1 = layers.Dense(128, activation='relu', name='layer_1')(inputs)  # capa oculta 1\n",
        "l_2 = layers.Dense(64, activation='relu', name='layer_2')(l_1)  # capa oculta 2\n",
        "l_3 = layers.Dense(32, activation='relu', name='layer_3')(l_2)  # capa oculta 3\n",
        "\n",
        "outputs = layers.Dense(1, activation='sigmoid', name='output_layer')(l_3)  # salida\n",
        "\n",
        "model_early_stopping = keras.Model(inputs=inputs, outputs=outputs, name='dont_overfit_model_early_stopping')"
      ],
      "metadata": {
        "id": "e3FFmxaJRY9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_early_stopping.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmAN2ZAERZni",
        "outputId": "a18ee7f2-336b-465f-b4a8-8947fd6c7588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dont_overfit_model_early_stopping\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 300)]             0         \n",
            "                                                                 \n",
            " layer_1 (Dense)             (None, 128)               38528     \n",
            "                                                                 \n",
            " layer_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " layer_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,897\n",
            "Trainable params: 48,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_early_stopping.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Jg6rNUm7Rgwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_early_stopping = model_early_stopping.fit(x,y,\n",
        "  batch_size=32,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        "  shuffle=True,\n",
        "callbacks=[es_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkSju5VcRoet",
        "outputId": "e848f7ff-aec1-4d95-8874-d18e2d9a55e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/7 [===>..........................] - ETA: 2s - loss: 0.7903 - accuracy: 0.4062WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 1s 25ms/step - loss: 0.6869 - accuracy: 0.6200 - val_loss: 0.6618 - val_accuracy: 0.7400\n",
            "Epoch 2/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4256 - accuracy: 0.8125WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7650 - val_loss: 0.6610 - val_accuracy: 0.7400\n",
            "Epoch 3/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4941 - accuracy: 0.6250WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3106 - accuracy: 0.8650 - val_loss: 0.6595 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1765 - accuracy: 0.9688WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2205 - accuracy: 0.9650 - val_loss: 0.6932 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.2238 - accuracy: 0.9688WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9900 - val_loss: 0.7456 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1062 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9900 - val_loss: 0.8002 - val_accuracy: 0.6800\n",
            "Epoch 7/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.8456 - val_accuracy: 0.6800\n",
            "Epoch 8/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0396 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0320 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.6800\n",
            "Epoch 10/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.6800\n",
            "Epoch 11/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0202 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.0352 - val_accuracy: 0.6800\n",
            "Epoch 12/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.6800\n",
            "Epoch 13/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.6800\n",
            "Epoch 14/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.6800\n",
            "Epoch 15/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.6800\n",
            "Epoch 16/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.6800\n",
            "Epoch 17/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.6800\n",
            "Epoch 18/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1855 - val_accuracy: 0.6800\n",
            "Epoch 19/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.6800\n",
            "Epoch 20/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.6800\n",
            "Epoch 21/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2295 - val_accuracy: 0.6800\n",
            "Epoch 22/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.6800\n",
            "Epoch 23/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.6800\n",
            "Epoch 24/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.6800\n",
            "Epoch 25/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.6800\n",
            "Epoch 26/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2790 - val_accuracy: 0.6800\n",
            "Epoch 27/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2871 - val_accuracy: 0.6800\n",
            "Epoch 28/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2940 - val_accuracy: 0.6800\n",
            "Epoch 29/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.8378e-04 - accuracy: 1.0000 - val_loss: 1.3000 - val_accuracy: 0.6800\n",
            "Epoch 30/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 9.1756e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.1376e-04 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.6800\n",
            "Epoch 31/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 8.4948e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.4696e-04 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.6800\n",
            "Epoch 32/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 7.9467e-04 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.6800\n",
            "Epoch 33/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.6781e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.4157e-04 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.6800\n",
            "Epoch 34/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 6.3187e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 6.9961e-04 - accuracy: 1.0000 - val_loss: 1.3366 - val_accuracy: 0.6800\n",
            "Epoch 35/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 6.7600e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.5701e-04 - accuracy: 1.0000 - val_loss: 1.3437 - val_accuracy: 0.6800\n",
            "Epoch 36/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.2479e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 6.1910e-04 - accuracy: 1.0000 - val_loss: 1.3498 - val_accuracy: 0.6800\n",
            "Epoch 37/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.4938e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 5.8491e-04 - accuracy: 1.0000 - val_loss: 1.3573 - val_accuracy: 0.6800\n",
            "Epoch 38/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.6028e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 5.5404e-04 - accuracy: 1.0000 - val_loss: 1.3640 - val_accuracy: 0.6800\n",
            "Epoch 39/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.3518e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.2576e-04 - accuracy: 1.0000 - val_loss: 1.3704 - val_accuracy: 0.6800\n",
            "Epoch 40/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.5487e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.9870e-04 - accuracy: 1.0000 - val_loss: 1.3760 - val_accuracy: 0.6800\n",
            "Epoch 41/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.2621e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.7343e-04 - accuracy: 1.0000 - val_loss: 1.3820 - val_accuracy: 0.6800\n",
            "Epoch 42/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.4723e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.5166e-04 - accuracy: 1.0000 - val_loss: 1.3874 - val_accuracy: 0.6800\n",
            "Epoch 43/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 5.2648e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.3023e-04 - accuracy: 1.0000 - val_loss: 1.3932 - val_accuracy: 0.6800\n",
            "Epoch 44/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.4055e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.1052e-04 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.6800\n",
            "Epoch 45/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.6500e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.9265e-04 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.6800\n",
            "Epoch 46/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.8938e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.7559e-04 - accuracy: 1.0000 - val_loss: 1.4103 - val_accuracy: 0.6800\n",
            "Epoch 47/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 3.2350e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5877e-04 - accuracy: 1.0000 - val_loss: 1.4161 - val_accuracy: 0.6800\n",
            "Epoch 48/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 4.1614e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4425e-04 - accuracy: 1.0000 - val_loss: 1.4203 - val_accuracy: 0.6800\n",
            "Epoch 49/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.9710e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3010e-04 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.6800\n",
            "Epoch 50/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 3.0874e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.1666e-04 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.6800\n",
            "Epoch 51/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 3.1564e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.0448e-04 - accuracy: 1.0000 - val_loss: 1.4356 - val_accuracy: 0.6800\n",
            "Epoch 52/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.7270e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.9305e-04 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.6800\n",
            "Epoch 53/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.8241e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.8181e-04 - accuracy: 1.0000 - val_loss: 1.4446 - val_accuracy: 0.6800\n",
            "Epoch 54/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.2875e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.7153e-04 - accuracy: 1.0000 - val_loss: 1.4490 - val_accuracy: 0.6800\n",
            "Epoch 55/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.6578e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.6214e-04 - accuracy: 1.0000 - val_loss: 1.4527 - val_accuracy: 0.6800\n",
            "Epoch 56/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.5553e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.5246e-04 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.6800\n",
            "Epoch 57/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.3378e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.4369e-04 - accuracy: 1.0000 - val_loss: 1.4597 - val_accuracy: 0.6800\n",
            "Epoch 58/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.1949e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.3503e-04 - accuracy: 1.0000 - val_loss: 1.4636 - val_accuracy: 0.6800\n",
            "Epoch 59/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.6049e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.2685e-04 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.6800\n",
            "Epoch 60/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.7642e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1955e-04 - accuracy: 1.0000 - val_loss: 1.4717 - val_accuracy: 0.6800\n",
            "Epoch 61/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.4992e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1237e-04 - accuracy: 1.0000 - val_loss: 1.4756 - val_accuracy: 0.6800\n",
            "Epoch 62/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.7623e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0543e-04 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.6800\n",
            "Epoch 63/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.5234e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.9902e-04 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.6800\n",
            "Epoch 64/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.1451e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.9283e-04 - accuracy: 1.0000 - val_loss: 1.4871 - val_accuracy: 0.6800\n",
            "Epoch 65/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.0738e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.8684e-04 - accuracy: 1.0000 - val_loss: 1.4905 - val_accuracy: 0.6800\n",
            "Epoch 66/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 2.0197e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8128e-04 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.6800\n",
            "Epoch 67/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.8768e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.7592e-04 - accuracy: 1.0000 - val_loss: 1.4972 - val_accuracy: 0.6800\n",
            "Epoch 68/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.8487e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7075e-04 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.6800\n",
            "Epoch 69/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.8361e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6600e-04 - accuracy: 1.0000 - val_loss: 1.5038 - val_accuracy: 0.6800\n",
            "Epoch 70/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.6648e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6132e-04 - accuracy: 1.0000 - val_loss: 1.5073 - val_accuracy: 0.6800\n",
            "Epoch 71/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.3112e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.5671e-04 - accuracy: 1.0000 - val_loss: 1.5108 - val_accuracy: 0.6800\n",
            "Epoch 72/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.6729e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.5246e-04 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6800\n",
            "Epoch 73/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0780e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.4830e-04 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.6800\n",
            "Epoch 74/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2738e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.4443e-04 - accuracy: 1.0000 - val_loss: 1.5204 - val_accuracy: 0.6800\n",
            "Epoch 75/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0090e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.4071e-04 - accuracy: 1.0000 - val_loss: 1.5238 - val_accuracy: 0.6800\n",
            "Epoch 76/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2044e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3722e-04 - accuracy: 1.0000 - val_loss: 1.5271 - val_accuracy: 0.6800\n",
            "Epoch 77/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.1314e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.3379e-04 - accuracy: 1.0000 - val_loss: 1.5301 - val_accuracy: 0.6800\n",
            "Epoch 78/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.3611e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.3037e-04 - accuracy: 1.0000 - val_loss: 1.5335 - val_accuracy: 0.6800\n",
            "Epoch 79/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2501e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.2718e-04 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.6800\n",
            "Epoch 80/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.1840e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.2398e-04 - accuracy: 1.0000 - val_loss: 1.5388 - val_accuracy: 0.6800\n",
            "Epoch 81/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.1766e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.2108e-04 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.6800\n",
            "Epoch 82/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2117e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.6800\n",
            "Epoch 83/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2374e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 1.5476 - val_accuracy: 0.6800\n",
            "Epoch 84/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 9.2055e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1279e-04 - accuracy: 1.0000 - val_loss: 1.5505 - val_accuracy: 0.6800\n",
            "Epoch 85/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0589e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.1000e-04 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0148e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0747e-04 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.3820e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0505e-04 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.1598e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0271e-04 - accuracy: 1.0000 - val_loss: 1.5618 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.2357e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 8.0521e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.8228e-05 - accuracy: 1.0000 - val_loss: 1.5676 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0144e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.6121e-05 - accuracy: 1.0000 - val_loss: 1.5706 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 9.0988e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 9.4002e-05 - accuracy: 1.0000 - val_loss: 1.5737 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 8.3402e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.2028e-05 - accuracy: 1.0000 - val_loss: 1.5760 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 9.9522e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 9.0003e-05 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 6.5213e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.7963e-05 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0737e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 8.6165e-05 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.0853e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.4315e-05 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.7000\n",
            "Epoch 98/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 7.1078e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.2517e-05 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.7000\n",
            "Epoch 99/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 8.8139e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.0863e-05 - accuracy: 1.0000 - val_loss: 1.5908 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 9.2047e-05 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_accurancy` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 7.9190e-05 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_early_stopping = pd.DataFrame(history_early_stopping.history)\n",
        "hist_early_stopping['epoch'] = history_early_stopping.epoch"
      ],
      "metadata": {
        "id": "rTbIXx2PVNjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_loss_accuracy_evolution(hist_early_stopping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "1kS5M-ApVOFw",
        "outputId": "078fb09d-118c-4062-c894-93561bdc3378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-82c8e133ed7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_loss_accuracy_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_early_stopping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'show_loss_accuracy_evolution' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 5**\n",
        "\n",
        "En el ejemplo en el que se aplican diferentes regularizadores en las capas ocultas del modelo pueden verse los resultados obtenidos.\n",
        "\n",
        "Comparar con los obtenidos por el primer modelo de ejemplo."
      ],
      "metadata": {
        "id": "cbJxXcyAWZtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 6**\n",
        "\n",
        "Además de las técnicas presentadas y aplicadas en esta actividad, ¿existen otras que podrían también haberse aplicado?\n",
        "\n",
        "Consulte internet, además de las notas técnicas, para responder a esta pregunta."
      ],
      "metadata": {
        "id": "LvcnrRAkWdrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 7**\n",
        "\n",
        "Se pide que el alumno construya un modelo similar al del primer ejemplo en el que:\n",
        "\n",
        "modifique la topología de la red (distinto número de capas, de neuronas, ...)\n",
        "se aplique dropout en al menos una de las capas\n",
        "se aplique early stopping durante el entrenamiento con un valor de patience no menor de 10)\n",
        "se aplique un regularizador (L1, L2 ó L1_L2) en al menos una de las capas\n",
        "analice los resultados"
      ],
      "metadata": {
        "id": "brlLjnUcWg2K"
      }
    }
  ]
}